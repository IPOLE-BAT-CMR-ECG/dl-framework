{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "project_root = str(Path().absolute().parent)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.data.unified import UnifiedDataset\n",
    "from src.data.dataset import DatasetModality\n",
    "\n",
    "data_root = Path(project_root) / \"data\"\n",
    "arrhythmia_data = UnifiedDataset(\n",
    "    data_root, modality=DatasetModality.ECG, dataset_key=\"arrhythmia\"\n",
    ")\n",
    "\n",
    "records = arrhythmia_data.get_all_record_ids()\n",
    "metadata_store = arrhythmia_data.metadata_store\n",
    "df = pd.DataFrame(\n",
    "    [{**metadata_store.get(record_id), \"record_id\": record_id} for record_id in records]\n",
    ")\n",
    "df[\"labels\"] = [\n",
    "    arrhythmia_data[record_id].preprocessed_record.target_labels\n",
    "    for record_id in records\n",
    "]\n",
    "\n",
    "import ast\n",
    "\n",
    "df[\"labels_metadata\"] = df[\"labels_metadata\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "df[\"group\"] = df[\"labels_metadata\"].apply(\n",
    "    lambda x: x[0].get(\"group\") if isinstance(x, list) else None\n",
    ")\n",
    "\n",
    "del arrhythmia_data, metadata_store\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# high retina\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# set default size\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex_category\"] = df[\"is_male\"].map({1: \"Male\", 0: \"Female\"})\n",
    "df.loc[df[\"is_male\"].isna(), \"sex_category\"] = \"Missing\"\n",
    "\n",
    "missing_age = df[\"age\"].isna().sum()\n",
    "missing_sex = df[\"is_male\"].isna().sum()\n",
    "\n",
    "print(f\"Total missing age values: {missing_age}\")\n",
    "print(f\"Total missing sex values: {missing_sex}\")\n",
    "\n",
    "sex_counts = df[\"sex_category\"].value_counts()\n",
    "total_records = len(df)\n",
    "percentages = (sex_counts / total_records * 100).round(2)  # Round to 1 decimal place\n",
    "\n",
    "# Set up the figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "# ---- Violin Plot: Age Distribution by Sex ----\n",
    "sns.violinplot(\n",
    "    x=\"sex_category\", y=\"age\", data=df, palette=\"muted\", inner=\"quartile\", ax=axes[0]\n",
    ")\n",
    "\n",
    "axes[0].set_xlabel(\"Sex Category\")\n",
    "axes[0].set_ylabel(\"Age\")\n",
    "\n",
    "# ---- Bar Plot: Distribution of Sex Categories ----\n",
    "barplot = sns.countplot(x=\"sex_category\", data=df, palette=\"muted\", ax=axes[1])\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for p in barplot.patches:\n",
    "    height = p.get_height()\n",
    "    barplot.annotate(\n",
    "        f\"{(height / total_records * 100):.2f}% (n={int(height)})\",  # Convert count to percentage\n",
    "        (p.get_x() + p.get_width() / 2, height),  # Position\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "axes[1].set_xlabel(\"Sex Category\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "# Explode the 'labels_metadata' column to have one row per label\n",
    "df_exploded = df.explode(\"labels_metadata\")\n",
    "\n",
    "# Extract relevant fields\n",
    "df_exploded[\"integration_name\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: x.get(\"integration_name\")\n",
    ")\n",
    "df_exploded[\"group\"] = df_exploded[\"labels_metadata\"].apply(lambda x: x.get(\"group\"))\n",
    "\n",
    "# Count occurrences of each integration name\n",
    "label_counts = (\n",
    "    df_exploded.groupby([\"integration_name\", \"group\"]).size().reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# Sort by count\n",
    "label_counts = label_counts.sort_values(by=\"count\", ascending=False)\n",
    "\n",
    "# Calculate percentages\n",
    "total_count = label_counts[\"count\"].sum()\n",
    "label_counts[\"percentage\"] = (label_counts[\"count\"] / total_count) * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(\n",
    "    data=label_counts, x=\"integration_name\", y=\"count\", hue=\"group\", dodge=False\n",
    ")\n",
    "\n",
    "# annotate with percentages\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if height == 0:\n",
    "        continue\n",
    "    ax.text(\n",
    "        p.get_x() + p.get_width() / 2.0,\n",
    "        height + 3,\n",
    "        f\"{height / total_count * 100:.2f}%\",\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend(title=\"Group\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results epoch 50\n",
    "\n",
    "metrics = {\n",
    "    \"test_loss\": 0.1731889545917511,\n",
    "    \"test/accuracy\": 0.9585899114608765,\n",
    "    \"test/precision\": 1.4069647749395141e29,\n",
    "    \"test/recall\": 0.5189249515533447,\n",
    "    \"test/f1\": 0.5026060938835144,\n",
    "    \"test/specificity\": 0.970903217792511,\n",
    "    \"test/auroc/10370003\": 0.9716390371322632,\n",
    "    \"test/auroc/164889003\": 0.9922537803649902,\n",
    "    \"test/auroc/164909002\": 0.9914255142211914,\n",
    "    \"test/auroc/164917005\": 0.9407635927200317,\n",
    "    \"test/auroc/251146004\": 0.8816485404968262,\n",
    "    \"test/auroc/270492004\": 0.9613152742385864,\n",
    "    \"test/auroc/27885002\": 0.970839262008667,\n",
    "    \"test/auroc/284470004\": 0.7667648792266846,\n",
    "    \"test/auroc/39732003\": 0.9763144254684448,\n",
    "    \"test/auroc/426177001\": 0.9944480657577515,\n",
    "    \"test/auroc/426783006\": 0.9580038785934448,\n",
    "    \"test/auroc/427084000\": 0.9854577779769897,\n",
    "    \"test/auroc/427172004\": 0.9058138132095337,\n",
    "    \"test/auroc/445118002\": 0.9812264442443848,\n",
    "    \"test/auroc/47665007\": 0.9816645383834839,\n",
    "    \"test/auroc/55827005\": 0.8618090152740479,\n",
    "    \"test/auroc/55930002\": 0.9100780487060547,\n",
    "    \"test/auroc/713427006\": 0.9892495274543762,\n",
    "    \"test/auroc/74390002\": 0.9732459187507629,\n",
    "    \"test/auroc/89792004\": 0.9881136417388916,\n",
    "    \"test/average_precision/10370003\": 0.7705467343330383,\n",
    "    \"test/average_precision/164889003\": 0.9695818424224854,\n",
    "    \"test/average_precision/164909002\": 0.5808265805244446,\n",
    "    \"test/average_precision/164917005\": 0.43110114336013794,\n",
    "    \"test/average_precision/251146004\": 0.1984182447195053,\n",
    "    \"test/average_precision/270492004\": 0.644189178943634,\n",
    "    \"test/average_precision/27885002\": 0.07638506591320038,\n",
    "    \"test/average_precision/284470004\": 0.1017557680606842,\n",
    "    \"test/average_precision/39732003\": 0.4860231876373291,\n",
    "    \"test/average_precision/426177001\": 0.9889308214187622,\n",
    "    \"test/average_precision/426783006\": 0.9226680994033813,\n",
    "    \"test/average_precision/427084000\": 0.9516099095344543,\n",
    "    \"test/average_precision/427172004\": 0.43971166014671326,\n",
    "    \"test/average_precision/445118002\": 0.39616161584854126,\n",
    "    \"test/average_precision/47665007\": 0.5112760066986084,\n",
    "    \"test/average_precision/55827005\": 0.5109458565711975,\n",
    "    \"test/average_precision/55930002\": 0.8367711305618286,\n",
    "    \"test/average_precision/713427006\": 0.6500297784805298,\n",
    "    \"test/average_precision/74390002\": 0.07447796314954758,\n",
    "    \"test/average_precision/89792004\": 0.3549346923828125,\n",
    "    \"test/accuracy/10370003\": 0.9876543283462524,\n",
    "    \"test/accuracy/164889003\": 0.961624264717102,\n",
    "    \"test/accuracy/164909002\": 0.9897367358207703,\n",
    "    \"test/accuracy/164917005\": 0.9745649099349976,\n",
    "    \"test/accuracy/251146004\": 0.9730774760246277,\n",
    "    \"test/accuracy/270492004\": 0.981109619140625,\n",
    "    \"test/accuracy/27885002\": 0.9979175925254822,\n",
    "    \"test/accuracy/284470004\": 0.9702513813972473,\n",
    "    \"test/accuracy/39732003\": 0.966830313205719,\n",
    "    \"test/accuracy/426177001\": 0.9574594497680664,\n",
    "    \"test/accuracy/426783006\": 0.9308344721794128,\n",
    "    \"test/accuracy/427084000\": 0.9570132493972778,\n",
    "    \"test/accuracy/427172004\": 0.9756061434745789,\n",
    "    \"test/accuracy/445118002\": 0.9869105815887451,\n",
    "    \"test/accuracy/47665007\": 0.9815558791160583,\n",
    "    \"test/accuracy/55827005\": 0.7396995425224304,\n",
    "    \"test/accuracy/55930002\": 0.8594377636909485,\n",
    "    \"test/accuracy/713427006\": 0.9839357137680054,\n",
    "    \"test/accuracy/74390002\": 0.9985125660896301,\n",
    "    \"test/accuracy/89792004\": 0.9980663657188416,\n",
    "    \"test/precision/10370003\": 0.8640000224113464,\n",
    "    \"test/precision/164889003\": 0.8880982995033264,\n",
    "    \"test/precision/164909002\": 0.43877550959587097,\n",
    "    \"test/precision/164917005\": 0.5166666507720947,\n",
    "    \"test/precision/251146004\": 0.3461538553237915,\n",
    "    \"test/precision/270492004\": 0.6928104758262634,\n",
    "    \"test/precision/27885002\": 0.0,\n",
    "    \"test/precision/284470004\": 0.1428571492433548,\n",
    "    \"test/precision/39732003\": 0.5098814368247986,\n",
    "    \"test/precision/426177001\": 0.8998499512672424,\n",
    "    \"test/precision/426783006\": 0.94259113073349,\n",
    "    \"test/precision/427084000\": 0.9147679209709167,\n",
    "    \"test/precision/427172004\": 0.7567567825317383,\n",
    "    \"test/precision/445118002\": 0.31460675597190857,\n",
    "    \"test/precision/47665007\": 0.5546875,\n",
    "    \"test/precision/55827005\": 0.32277143001556396,\n",
    "    \"test/precision/55930002\": 0.7691908478736877,\n",
    "    \"test/precision/713427006\": 0.6094420552253723,\n",
    "    \"test/precision/74390002\": 0.0,\n",
    "    \"test/precision/89792004\": 1.0,\n",
    "    \"test/recall/10370003\": 0.6206896305084229,\n",
    "    \"test/recall/164889003\": 0.9417009353637695,\n",
    "    \"test/recall/164909002\": 0.7543859481811523,\n",
    "    \"test/recall/164917005\": 0.35428571701049805,\n",
    "    \"test/recall/251146004\": 0.05202312022447586,\n",
    "    \"test/recall/270492004\": 0.5698924660682678,\n",
    "    \"test/recall/27885002\": 0.0,\n",
    "    \"test/recall/284470004\": 0.0051282052882015705,\n",
    "    \"test/recall/39732003\": 0.5657894611358643,\n",
    "    \"test/recall/426177001\": 0.9921422600746155,\n",
    "    \"test/recall/426783006\": 0.7565379738807678,\n",
    "    \"test/recall/427084000\": 0.8522012829780579,\n",
    "    \"test/recall/427172004\": 0.2772277295589447,\n",
    "    \"test/recall/445118002\": 0.5090909004211426,\n",
    "    \"test/recall/47665007\": 0.5144927501678467,\n",
    "    \"test/recall/55827005\": 0.8386388421058655,\n",
    "    \"test/recall/55930002\": 0.7478567957878113,\n",
    "    \"test/recall/713427006\": 0.893081784248352,\n",
    "    \"test/recall/74390002\": 0.0,\n",
    "    \"test/recall/89792004\": 0.13333334028720856,\n",
    "    \"test/f1/10370003\": 0.7224080562591553,\n",
    "    \"test/f1/164889003\": 0.9141145348548889,\n",
    "    \"test/f1/164909002\": 0.5548387169837952,\n",
    "    \"test/f1/164917005\": 0.4203389883041382,\n",
    "    \"test/f1/251146004\": 0.09045226126909256,\n",
    "    \"test/f1/270492004\": 0.6253687143325806,\n",
    "    \"test/f1/27885002\": 0.0,\n",
    "    \"test/f1/284470004\": 0.009900989942252636,\n",
    "    \"test/f1/39732003\": 0.5363825559616089,\n",
    "    \"test/f1/426177001\": 0.9437450766563416,\n",
    "    \"test/f1/426783006\": 0.8393782377243042,\n",
    "    \"test/f1/427084000\": 0.8823769092559814,\n",
    "    \"test/f1/427172004\": 0.4057970941066742,\n",
    "    \"test/f1/445118002\": 0.3888888955116272,\n",
    "    \"test/f1/47665007\": 0.5338345766067505,\n",
    "    \"test/f1/55827005\": 0.4661378860473633,\n",
    "    \"test/f1/55930002\": 0.7583737969398499,\n",
    "    \"test/f1/713427006\": 0.7244898080825806,\n",
    "    \"test/f1/74390002\": 0.0,\n",
    "    \"test/f1/89792004\": 0.23529411852359772,\n",
    "    \"test/specificity/10370003\": 0.997404158115387,\n",
    "    \"test/specificity/164889003\": 0.9671415090560913,\n",
    "    \"test/specificity/164909002\": 0.9917491674423218,\n",
    "    \"test/specificity/164917005\": 0.9911423325538635,\n",
    "    \"test/specificity/251146004\": 0.9974045753479004,\n",
    "    \"test/specificity/270492004\": 0.9928101301193237,\n",
    "    \"test/specificity/27885002\": 0.9995530247688293,\n",
    "    \"test/specificity/284470004\": 0.9990808963775635,\n",
    "    \"test/specificity/39732003\": 0.9809083938598633,\n",
    "    \"test/specificity/426177001\": 0.9379791021347046,\n",
    "    \"test/specificity/426783006\": 0.9855384230613708,\n",
    "    \"test/specificity/427084000\": 0.9814713001251221,\n",
    "    \"test/specificity/427172004\": 0.9972397089004517,\n",
    "    \"test/specificity/445118002\": 0.9908518195152283,\n",
    "    \"test/specificity/47665007\": 0.9913439750671387,\n",
    "    \"test/specificity/55827005\": 0.7241913080215454,\n",
    "    \"test/specificity/55930002\": 0.9061181545257568,\n",
    "    \"test/specificity/713427006\": 0.9861364960670471,\n",
    "    \"test/specificity/74390002\": 1.0,\n",
    "    \"test/specificity/89792004\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the per-class F1 scores (from provided table)\n",
    "f1_scores = {\n",
    "    k.split(\"/\")[-1]: v for k, v in metrics.items() if k.startswith(\"test/f1/\")\n",
    "}\n",
    "\n",
    "# multiply by 100 for percentage\n",
    "f1_scores = {k: v * 100 for k, v in f1_scores.items()}\n",
    "\n",
    "# Step 1: Extract occurrences from `labels_metadata`\n",
    "df_exploded = df.explode(\"labels_metadata\")\n",
    "\n",
    "# Ensure 'labels_metadata' is in dictionary format\n",
    "df_exploded[\"labels_metadata\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Extract relevant information\n",
    "df_exploded[\"integration_code\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: x.get(\"integration_code\")\n",
    ")\n",
    "df_exploded[\"integration_name\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: x.get(\"integration_name\")\n",
    ")\n",
    "\n",
    "# Compute occurrence count of each integration name\n",
    "label_counts = (\n",
    "    df_exploded[\"integration_name\"].value_counts(normalize=True) * 100\n",
    ")  # Convert to percentage\n",
    "label_counts = label_counts.reset_index()\n",
    "label_counts.columns = [\"Integration Name\", \"Distribution (%)\"]\n",
    "\n",
    "# Step 2: Map integration names to F1 scores\n",
    "integration_map = (\n",
    "    df_exploded[[\"integration_code\", \"integration_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .set_index(\"integration_code\")[\"integration_name\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Create a DataFrame for F1 scores and match with integration names\n",
    "df_f1 = pd.DataFrame(list(f1_scores.items()), columns=[\"Integration Code\", \"F1-score\"])\n",
    "df_f1[\"Integration Name\"] = df_f1[\"Integration Code\"].map(integration_map)\n",
    "\n",
    "# Merge with label distribution data\n",
    "df_final = pd.merge(label_counts, df_f1, on=\"Integration Name\", how=\"left\").dropna()\n",
    "\n",
    "# Step 3: Sort by occurrence percentage\n",
    "df_final = df_final.sort_values(by=\"Distribution (%)\", ascending=False)\n",
    "\n",
    "# Normalize F1-score for color mapping\n",
    "norm = plt.Normalize(df_final[\"F1-score\"].min(), df_final[\"F1-score\"].max())\n",
    "cmap = plt.cm.RdYlGn  # Colormap from red to green\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create horizontal barplot using distribution as x-axis\n",
    "bars = ax.barh(\n",
    "    df_final[\"Integration Name\"],\n",
    "    df_final[\"Distribution (%)\"],\n",
    "    color=cmap(norm(df_final[\"F1-score\"])),\n",
    ")\n",
    "\n",
    "# Annotate each bar with the F1-score\n",
    "for bar, score in zip(bars, df_final[\"F1-score\"]):\n",
    "    width = bar.get_width()\n",
    "    ax.text(\n",
    "        width + 0.3,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{round(score)}\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Fixes colorbar issue\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"F1-score (%)\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(\"Distribution (%)\")\n",
    "ax.set_ylabel(\"Label\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.xlim(0, df_final[\"Distribution (%)\"].max() + 5)  # Slight padding on x-axis\n",
    "plt.gca().invert_yaxis()  # Highest occurrence at top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate statistics\n",
    "x = df_final[\"Distribution (%)\"]\n",
    "y = df_final[\"F1-score\"]\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "r_squared = r_value**2\n",
    "equation = f\"y = {slope:.2f}x + {intercept:.2f}\"\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 8)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Create figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Scatter plot with distribution density\n",
    "sns.regplot(\n",
    "    x=x,\n",
    "    y=y,\n",
    "    scatter_kws={\"s\": 80, \"alpha\": 0.8, \"edgecolor\": \"w\", \"linewidths\": 0.5},\n",
    "    line_kws={\"color\": \"#d62728\", \"linestyle\": \"--\", \"linewidth\": 1.5},\n",
    "    ci=95,  # 95% confidence interval\n",
    ")\n",
    "\n",
    "# Add statistical annotations\n",
    "stats_text = (\n",
    "    f\"Pearson $r$ = {r_value:.2f}\\n\" f\"$p$ = {p_value:.4f}\\n\" f\"$n$ = {len(x)} classes\"\n",
    ")\n",
    "\n",
    "ax.text(\n",
    "    0.95,\n",
    "    0.15,\n",
    "    stats_text,\n",
    "    transform=ax.transAxes,\n",
    "    fontfamily=\"monospace\",\n",
    "    fontsize=10,\n",
    "    verticalalignment=\"top\",\n",
    "    horizontalalignment=\"right\",\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.9, edgecolor=\"0.8\"),\n",
    ")\n",
    "\n",
    "# Axis labels with units\n",
    "ax.set_xlabel(\"Label Prevalence (% of total samples)\", fontsize=12, labelpad=10)\n",
    "ax.set_ylabel(\"F1-Score (%)\", fontsize=12, labelpad=10)\n",
    "\n",
    "# Set axis limits with buffer\n",
    "ax.set_xlim(left=-1, right=x.max() * 1.1)\n",
    "ax.set_ylim(bottom=y.min() - 2, top=100 + 2)\n",
    "\n",
    "# Custom grid\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.6, which=\"both\")\n",
    "\n",
    "\n",
    "# print values\n",
    "print(\n",
    "    \"slope, intercept, r_value, p_value, std_err\",\n",
    "    slope,\n",
    "    intercept,\n",
    "    r_value,\n",
    "    p_value,\n",
    "    std_err,\n",
    ")\n",
    "\n",
    "# Use tight layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scores = {\n",
    "    k.split(\"/\")[-1]: v for k, v in metrics.items() if k.startswith(\"test/recall/\")\n",
    "}\n",
    "\n",
    "# multiply by 100 for percentage\n",
    "recall_scores = {k: v * 100 for k, v in recall_scores.items()}\n",
    "\n",
    "# Step 1: Extract occurrences from `labels_metadata`\n",
    "df_exploded = df.explode(\"labels_metadata\")\n",
    "\n",
    "# Ensure 'labels_metadata' is in dictionary format\n",
    "df_exploded[\"labels_metadata\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Extract relevant information\n",
    "df_exploded[\"integration_code\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: x.get(\"integration_code\")\n",
    ")\n",
    "df_exploded[\"integration_name\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: x.get(\"integration_name\")\n",
    ")\n",
    "\n",
    "# Compute occurrence count of each integration name\n",
    "label_counts = (\n",
    "    df_exploded[\"integration_name\"].value_counts(normalize=True) * 100\n",
    ")  # Convert to percentage\n",
    "label_counts = label_counts.reset_index()\n",
    "label_counts.columns = [\"Integration Name\", \"Distribution (%)\"]\n",
    "\n",
    "# Step 2: Map integration names to F1 scores\n",
    "integration_map = (\n",
    "    df_exploded[[\"integration_code\", \"integration_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .set_index(\"integration_code\")[\"integration_name\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Create a DataFrame for F1 scores and match with integration names\n",
    "df_f1 = pd.DataFrame(\n",
    "    list(recall_scores.items()), columns=[\"Integration Code\", \"Recall\"]\n",
    ")\n",
    "df_f1[\"Integration Name\"] = df_f1[\"Integration Code\"].map(integration_map)\n",
    "\n",
    "# Merge with label distribution data\n",
    "df_final = pd.merge(label_counts, df_f1, on=\"Integration Name\", how=\"left\").dropna()\n",
    "\n",
    "# Step 3: Sort by occurrence percentage\n",
    "df_final = df_final.sort_values(by=\"Distribution (%)\", ascending=False)\n",
    "\n",
    "# Normalize F1-score for color mapping\n",
    "norm = plt.Normalize(df_final[\"Recall\"].min(), df_final[\"Recall\"].max())\n",
    "cmap = plt.cm.RdYlGn  # Colormap from red to green\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create horizontal barplot using distribution as x-axis\n",
    "bars = ax.barh(\n",
    "    df_final[\"Integration Name\"],\n",
    "    df_final[\"Distribution (%)\"],\n",
    "    color=cmap(norm(df_final[\"Recall\"])),\n",
    ")\n",
    "\n",
    "# Annotate each bar with the F1-score\n",
    "for bar, score in zip(bars, df_final[\"Recall\"]):\n",
    "    width = bar.get_width()\n",
    "    ax.text(\n",
    "        width + 0.3,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{round(score)}\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Fixes colorbar issue\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Recall (%)\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(\"Distribution (%)\")\n",
    "ax.set_ylabel(\"Label\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.xlim(0, df_final[\"Distribution (%)\"].max() + 5)  # Slight padding on x-axis\n",
    "plt.gca().invert_yaxis()  # Highest occurrence at top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_scores = {\n",
    "    k.split(\"/\")[-1]: v for k, v in metrics.items() if k.startswith(\"test/precision/\")\n",
    "}\n",
    "\n",
    "# multiply by 100 for percentage\n",
    "precision_scores = {k: v * 100 for k, v in precision_scores.items()}\n",
    "\n",
    "# Step 1: Extract occurrences from `labels_metadata`\n",
    "df_exploded = df.explode(\"labels_metadata\")\n",
    "\n",
    "# Ensure 'labels_metadata' is in dictionary format\n",
    "df_exploded[\"labels_metadata\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "# Extract relevant information\n",
    "df_exploded[\"integration_code\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: x.get(\"integration_code\")\n",
    ")\n",
    "df_exploded[\"integration_name\"] = df_exploded[\"labels_metadata\"].apply(\n",
    "    lambda x: x.get(\"integration_name\")\n",
    ")\n",
    "\n",
    "# Compute occurrence count of each integration name\n",
    "label_counts = (\n",
    "    df_exploded[\"integration_name\"].value_counts(normalize=True) * 100\n",
    ")  # Convert to percentage\n",
    "label_counts = label_counts.reset_index()\n",
    "label_counts.columns = [\"Integration Name\", \"Distribution (%)\"]\n",
    "\n",
    "# Step 2: Map integration names to F1 scores\n",
    "integration_map = (\n",
    "    df_exploded[[\"integration_code\", \"integration_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .set_index(\"integration_code\")[\"integration_name\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Create a DataFrame for F1 scores and match with integration names\n",
    "df_f1 = pd.DataFrame(\n",
    "    list(precision_scores.items()), columns=[\"Integration Code\", \"Precision\"]\n",
    ")\n",
    "df_f1[\"Integration Name\"] = df_f1[\"Integration Code\"].map(integration_map)\n",
    "\n",
    "# Merge with label distribution data\n",
    "df_final = pd.merge(label_counts, df_f1, on=\"Integration Name\", how=\"left\").dropna()\n",
    "\n",
    "# Step 3: Sort by occurrence percentage\n",
    "df_final = df_final.sort_values(by=\"Distribution (%)\", ascending=False)\n",
    "\n",
    "# Normalize F1-score for color mapping\n",
    "norm = plt.Normalize(df_final[\"Precision\"].min(), df_final[\"Precision\"].max())\n",
    "cmap = plt.cm.RdYlGn  # Colormap from red to green\n",
    "\n",
    "# Create figure and axes\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create horizontal barplot using distribution as x-axis\n",
    "bars = ax.barh(\n",
    "    df_final[\"Integration Name\"],\n",
    "    df_final[\"Distribution (%)\"],\n",
    "    color=cmap(norm(df_final[\"Precision\"])),\n",
    ")\n",
    "\n",
    "# Annotate each bar with the F1-score\n",
    "for bar, score in zip(bars, df_final[\"Precision\"]):\n",
    "    width = bar.get_width()\n",
    "    ax.text(\n",
    "        width + 0.3,\n",
    "        bar.get_y() + bar.get_height() / 2,\n",
    "        f\"{round(score)}\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "        color=\"black\",\n",
    "    )\n",
    "\n",
    "# Add colorbar\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Fixes colorbar issue\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label(\"Precision (%)\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(\"Distribution (%)\")\n",
    "ax.set_ylabel(\"Label\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.xlim(0, df_final[\"Distribution (%)\"].max() + 5)  # Slight padding on x-axis\n",
    "plt.gca().invert_yaxis()  # Highest occurrence at top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
